{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10bf0f34",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-15T13:09:01.612526Z",
     "iopub.status.busy": "2021-12-15T13:09:01.610695Z",
     "iopub.status.idle": "2021-12-15T13:09:07.654210Z",
     "shell.execute_reply": "2021-12-15T13:09:07.654672Z",
     "shell.execute_reply.started": "2021-12-15T08:00:46.730336Z"
    },
    "papermill": {
     "duration": 6.0648,
     "end_time": "2021-12-15T13:09:07.654986",
     "exception": false,
     "start_time": "2021-12-15T13:09:01.590186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Dropout, Dense, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aef232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T13:09:07.672305Z",
     "iopub.status.busy": "2021-12-15T13:09:07.671546Z",
     "iopub.status.idle": "2021-12-15T13:09:29.962920Z",
     "shell.execute_reply": "2021-12-15T13:09:29.962417Z",
     "shell.execute_reply.started": "2021-12-15T08:01:50.054806Z"
    },
    "papermill": {
     "duration": 22.30265,
     "end_time": "2021-12-15T13:09:29.963055",
     "exception": false,
     "start_time": "2021-12-15T13:09:07.660405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tabular-playground-series-dec-2021/train.csv')\n",
    "test = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv')\n",
    "\n",
    "\n",
    "\n",
    "for df in [train, test]:\n",
    "    df.drop(columns=['Soil_Type7', 'Soil_Type15','Soil_Type1'],inplace=True)\n",
    "    \n",
    "#feature engineering\n",
    "'''\n",
    "train['total_distance_to_water'] = np.sqrt((train['Horizontal_Distance_To_Hydrology'])**2 + (train['Vertical_Distance_To_Hydrology'])**2)\n",
    "train = train.drop(['Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology'], axis=1)\n",
    "\n",
    "test['total_distance_to_water'] = np.sqrt((test['Horizontal_Distance_To_Hydrology'])**2 + (test['Vertical_Distance_To_Hydrology'])**2)\n",
    "test = test.drop(['Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology'], axis=1)\n",
    "#train['total_shade'] = train['Hillshade_9am'] + train['Hillshade_Noon'] + train['Hillshade_3pm']\n",
    "train['mean_shade'] = (train['Hillshade_9am'] + train['Hillshade_Noon'] + train['Hillshade_3pm'])/3\n",
    "train= train.drop(['Hillshade_9am','Hillshade_Noon', 'Hillshade_3pm'],axis=1)\n",
    "\n",
    "test['mean_shade'] = (test['Hillshade_9am'] + test['Hillshade_Noon'] + test['Hillshade_3pm'])/3\n",
    "test= test.drop(['Hillshade_9am','Hillshade_Noon', 'Hillshade_3pm'],axis=1)\n",
    "'''\n",
    "train = train[train.Cover_Type != 5]\n",
    "X = train.drop(['Cover_Type','Id'], axis=1)\n",
    "le = LabelEncoder()\n",
    "y = pd.DataFrame(le.fit_transform(train.Cover_Type))\n",
    "X_test = test.drop('Id', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af425683",
   "metadata": {
    "papermill": {
     "duration": 0.00433,
     "end_time": "2021-12-15T13:09:29.972231",
     "exception": false,
     "start_time": "2021-12-15T13:09:29.967901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23203b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T13:09:29.999515Z",
     "iopub.status.busy": "2021-12-15T13:09:29.998680Z",
     "iopub.status.idle": "2021-12-15T13:09:47.963083Z",
     "shell.execute_reply": "2021-12-15T13:09:47.964946Z",
     "shell.execute_reply.started": "2021-12-14T19:17:37.187763Z"
    },
    "papermill": {
     "duration": 17.988244,
     "end_time": "2021-12-15T13:09:47.965153",
     "exception": false,
     "start_time": "2021-12-15T13:09:29.976909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 259.40 Mb (83.7% reduction)\n",
      "Mem. usage decreased to 57.22 Mb (85.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16',\n",
    "                'float32', 'float64']\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype=='bool':\n",
    "            df[col] = df[col].astype(int)\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            #change int type to lowest poss\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "X = reduce_mem_usage(X)\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8306cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-15T13:09:47.992142Z",
     "iopub.status.busy": "2021-12-15T13:09:47.991365Z",
     "iopub.status.idle": "2021-12-15T17:45:27.354050Z",
     "shell.execute_reply": "2021-12-15T17:45:27.353121Z",
     "shell.execute_reply.started": "2021-12-14T19:17:50.28742Z"
    },
    "papermill": {
     "duration": 16539.379367,
     "end_time": "2021-12-15T17:45:27.354209",
     "exception": false,
     "start_time": "2021-12-15T13:09:47.974842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 13:09:53.514468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:53.612894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:53.613613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:53.614711: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-15 13:09:53.616225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:53.616896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:53.617502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:55.178415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:55.179262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:55.179913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 13:09:55.180495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2021-12-15 13:09:56.626510: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1468799592 exceeds 10% of free system memory.\n",
      "2021-12-15 13:09:58.084404: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1468799592 exceeds 10% of free system memory.\n",
      "2021-12-15 13:09:59.281111: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 21s 4ms/step - loss: 0.1460 - acc: 0.9425 - val_loss: 0.1067 - val_acc: 0.9539\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1064 - acc: 0.9537 - val_loss: 0.0983 - val_acc: 0.9570\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1009 - acc: 0.9555 - val_loss: 0.0938 - val_acc: 0.9583\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0976 - acc: 0.9564 - val_loss: 0.0917 - val_acc: 0.9588\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0950 - acc: 0.9573 - val_loss: 0.0904 - val_acc: 0.9592\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0935 - acc: 0.9578 - val_loss: 0.0899 - val_acc: 0.9592\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0919 - acc: 0.9583 - val_loss: 0.0881 - val_acc: 0.9601\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0909 - acc: 0.9586 - val_loss: 0.0862 - val_acc: 0.9603\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0898 - acc: 0.9590 - val_loss: 0.0883 - val_acc: 0.9596\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0887 - acc: 0.9593 - val_loss: 0.0861 - val_acc: 0.9606\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0880 - acc: 0.9595 - val_loss: 0.0855 - val_acc: 0.9603\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0873 - acc: 0.9597 - val_loss: 0.0840 - val_acc: 0.9606\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0868 - acc: 0.9599 - val_loss: 0.0850 - val_acc: 0.9604\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0860 - acc: 0.9602 - val_loss: 0.0841 - val_acc: 0.9609\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0854 - acc: 0.9603 - val_loss: 0.0836 - val_acc: 0.9608\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0851 - acc: 0.9603 - val_loss: 0.0834 - val_acc: 0.9613\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0845 - acc: 0.9606 - val_loss: 0.0824 - val_acc: 0.9612\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0840 - acc: 0.9606 - val_loss: 0.0828 - val_acc: 0.9611\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0836 - acc: 0.9608 - val_loss: 0.0837 - val_acc: 0.9610\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0832 - acc: 0.9608 - val_loss: 0.0823 - val_acc: 0.9613\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0828 - acc: 0.9610 - val_loss: 0.0823 - val_acc: 0.9611\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0825 - acc: 0.9611 - val_loss: 0.0822 - val_acc: 0.9612\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0823 - acc: 0.9612 - val_loss: 0.0818 - val_acc: 0.9612\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0819 - acc: 0.9612 - val_loss: 0.0821 - val_acc: 0.9609\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0818 - acc: 0.9613 - val_loss: 0.0812 - val_acc: 0.9614\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0815 - acc: 0.9614 - val_loss: 0.0817 - val_acc: 0.9612\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0813 - acc: 0.9615 - val_loss: 0.0813 - val_acc: 0.9612\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0811 - acc: 0.9615 - val_loss: 0.0820 - val_acc: 0.9615\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0810 - acc: 0.9615 - val_loss: 0.0820 - val_acc: 0.9610\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0808 - acc: 0.9616 - val_loss: 0.0807 - val_acc: 0.9613\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0805 - acc: 0.9617 - val_loss: 0.0807 - val_acc: 0.9617\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0804 - acc: 0.9617 - val_loss: 0.0808 - val_acc: 0.9614\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0803 - acc: 0.9618 - val_loss: 0.0803 - val_acc: 0.9614\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0802 - acc: 0.9618 - val_loss: 0.0804 - val_acc: 0.9617\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0800 - acc: 0.9619 - val_loss: 0.0807 - val_acc: 0.9617\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0799 - acc: 0.9619 - val_loss: 0.0801 - val_acc: 0.9617\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0798 - acc: 0.9618 - val_loss: 0.0801 - val_acc: 0.9615\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0796 - acc: 0.9620 - val_loss: 0.0807 - val_acc: 0.9614\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0795 - acc: 0.9620 - val_loss: 0.0803 - val_acc: 0.9614\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0794 - acc: 0.9620 - val_loss: 0.0807 - val_acc: 0.9615\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0793 - acc: 0.9620 - val_loss: 0.0801 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0775 - acc: 0.9626 - val_loss: 0.0787 - val_acc: 0.9619\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0772 - acc: 0.9627 - val_loss: 0.0785 - val_acc: 0.9621\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0771 - acc: 0.9627 - val_loss: 0.0787 - val_acc: 0.9619\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9627 - val_loss: 0.0785 - val_acc: 0.9620\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0769 - acc: 0.9628 - val_loss: 0.0785 - val_acc: 0.9619\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0769 - acc: 0.9627 - val_loss: 0.0788 - val_acc: 0.9620\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0769 - acc: 0.9628 - val_loss: 0.0788 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0758 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0781 - val_acc: 0.9620\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0758 - acc: 0.9631 - val_loss: 0.0780 - val_acc: 0.9621\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9632 - val_loss: 0.0779 - val_acc: 0.9620\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0782 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9633 - val_loss: 0.0775 - val_acc: 0.9622\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0750 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9622\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0750 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0747 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9623\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0746 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 17s 4ms/step - loss: 0.0747 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9622\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0746 - acc: 0.9636 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0746 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9622\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0746 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0746 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9622\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0746 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9622\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0746 - acc: 0.9637 - val_loss: 0.0775 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9637 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0774 - val_acc: 0.9621\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0743 - acc: 0.9637 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0743 - acc: 0.9637 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0742 - acc: 0.9637 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0743 - acc: 0.9637 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0743 - acc: 0.9635 - val_loss: 0.0774 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0743 - acc: 0.9637 - val_loss: 0.0774 - val_acc: 0.9621\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0742 - acc: 0.9637 - val_loss: 0.0774 - val_acc: 0.9621\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0742 - acc: 0.9638 - val_loss: 0.0774 - val_acc: 0.9622\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 13:35:53.590950: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0.0 : Accuracy: 0.96220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 13:36:04.752735: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1468799592 exceeds 10% of free system memory.\n",
      "2021-12-15 13:36:06.197411: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1468799592 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.1447 - acc: 0.9433 - val_loss: 0.1048 - val_acc: 0.9548\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1069 - acc: 0.9537 - val_loss: 0.1020 - val_acc: 0.9554\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1011 - acc: 0.9555 - val_loss: 0.0932 - val_acc: 0.9583\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0978 - acc: 0.9566 - val_loss: 0.0931 - val_acc: 0.9582\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0953 - acc: 0.9573 - val_loss: 0.0924 - val_acc: 0.9584\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0934 - acc: 0.9579 - val_loss: 0.0885 - val_acc: 0.9597\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0922 - acc: 0.9583 - val_loss: 0.0881 - val_acc: 0.9597\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 20s 5ms/step - loss: 0.0911 - acc: 0.9586 - val_loss: 0.0873 - val_acc: 0.9597\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0901 - acc: 0.9589 - val_loss: 0.0855 - val_acc: 0.9604\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0894 - acc: 0.9591 - val_loss: 0.0858 - val_acc: 0.9602\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0885 - acc: 0.9595 - val_loss: 0.0862 - val_acc: 0.9600\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0879 - acc: 0.9596 - val_loss: 0.0856 - val_acc: 0.9601\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0872 - acc: 0.9598 - val_loss: 0.0845 - val_acc: 0.9605\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0866 - acc: 0.9600 - val_loss: 0.0843 - val_acc: 0.9603\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0858 - acc: 0.9602 - val_loss: 0.0832 - val_acc: 0.9609\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0854 - acc: 0.9604 - val_loss: 0.0837 - val_acc: 0.9608\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0850 - acc: 0.9605 - val_loss: 0.0828 - val_acc: 0.9609\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0843 - acc: 0.9606 - val_loss: 0.0824 - val_acc: 0.9611\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0840 - acc: 0.9608 - val_loss: 0.0839 - val_acc: 0.9608\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0836 - acc: 0.9609 - val_loss: 0.0837 - val_acc: 0.9605\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0834 - acc: 0.9609 - val_loss: 0.0818 - val_acc: 0.9612\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0830 - acc: 0.9611 - val_loss: 0.0828 - val_acc: 0.9606\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0829 - acc: 0.9610 - val_loss: 0.0818 - val_acc: 0.9611\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0826 - acc: 0.9611 - val_loss: 0.0816 - val_acc: 0.9613\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0823 - acc: 0.9612 - val_loss: 0.0823 - val_acc: 0.9610\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0821 - acc: 0.9612 - val_loss: 0.0812 - val_acc: 0.9613\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0819 - acc: 0.9614 - val_loss: 0.0810 - val_acc: 0.9613\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0816 - acc: 0.9614 - val_loss: 0.0805 - val_acc: 0.9615\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0817 - acc: 0.9614 - val_loss: 0.0806 - val_acc: 0.9615\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0813 - acc: 0.9615 - val_loss: 0.0808 - val_acc: 0.9611\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0812 - acc: 0.9615 - val_loss: 0.0808 - val_acc: 0.9615\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0811 - acc: 0.9615 - val_loss: 0.0808 - val_acc: 0.9614\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0809 - acc: 0.9616 - val_loss: 0.0812 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0790 - acc: 0.9621 - val_loss: 0.0791 - val_acc: 0.9615\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0787 - acc: 0.9622 - val_loss: 0.0791 - val_acc: 0.9620\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0787 - acc: 0.9623 - val_loss: 0.0786 - val_acc: 0.9618\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0785 - acc: 0.9622 - val_loss: 0.0788 - val_acc: 0.9619\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0785 - acc: 0.9623 - val_loss: 0.0792 - val_acc: 0.9617\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0784 - acc: 0.9624 - val_loss: 0.0788 - val_acc: 0.9618\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0783 - acc: 0.9624 - val_loss: 0.0791 - val_acc: 0.9615\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0782 - acc: 0.9624 - val_loss: 0.0787 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0772 - acc: 0.9628 - val_loss: 0.0784 - val_acc: 0.9619\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9629 - val_loss: 0.0784 - val_acc: 0.9617\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9628 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0770 - acc: 0.9628 - val_loss: 0.0784 - val_acc: 0.9618\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0769 - acc: 0.9628 - val_loss: 0.0780 - val_acc: 0.9619\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0768 - acc: 0.9629 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0768 - acc: 0.9629 - val_loss: 0.0780 - val_acc: 0.9619\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0767 - acc: 0.9630 - val_loss: 0.0783 - val_acc: 0.9618\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0767 - acc: 0.9629 - val_loss: 0.0782 - val_acc: 0.9617\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0767 - acc: 0.9629 - val_loss: 0.0780 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9631 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9631 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0759 - acc: 0.9632 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0775 - val_acc: 0.9619\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0774 - val_acc: 0.9621\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0774 - val_acc: 0.9620\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0774 - val_acc: 0.9620\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0774 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "Fold 0.1 : Accuracy: 0.96206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 14:02:40.737964: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1468799592 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1444 - acc: 0.9431 - val_loss: 0.1057 - val_acc: 0.9546\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1065 - acc: 0.9537 - val_loss: 0.0972 - val_acc: 0.9572\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1007 - acc: 0.9555 - val_loss: 0.0986 - val_acc: 0.9567\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0976 - acc: 0.9566 - val_loss: 0.0917 - val_acc: 0.9590\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0950 - acc: 0.9574 - val_loss: 0.0893 - val_acc: 0.9599\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0934 - acc: 0.9580 - val_loss: 0.0895 - val_acc: 0.9594\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0920 - acc: 0.9583 - val_loss: 0.0862 - val_acc: 0.9603\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0907 - acc: 0.9588 - val_loss: 0.0856 - val_acc: 0.9607\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0898 - acc: 0.9589 - val_loss: 0.0849 - val_acc: 0.9609\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0890 - acc: 0.9592 - val_loss: 0.0866 - val_acc: 0.9600\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0884 - acc: 0.9595 - val_loss: 0.0863 - val_acc: 0.9601\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0874 - acc: 0.9597 - val_loss: 0.0839 - val_acc: 0.9610\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0868 - acc: 0.9599 - val_loss: 0.0833 - val_acc: 0.9611\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0863 - acc: 0.9599 - val_loss: 0.0856 - val_acc: 0.9600\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0856 - acc: 0.9603 - val_loss: 0.0826 - val_acc: 0.9613\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0853 - acc: 0.9604 - val_loss: 0.0825 - val_acc: 0.9609\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0847 - acc: 0.9605 - val_loss: 0.0823 - val_acc: 0.9613\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0844 - acc: 0.9606 - val_loss: 0.0828 - val_acc: 0.9611\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0840 - acc: 0.9608 - val_loss: 0.0819 - val_acc: 0.9613\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0837 - acc: 0.9608 - val_loss: 0.0811 - val_acc: 0.9616\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0835 - acc: 0.9609 - val_loss: 0.0815 - val_acc: 0.9617\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0829 - acc: 0.9611 - val_loss: 0.0810 - val_acc: 0.9616\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0827 - acc: 0.9611 - val_loss: 0.0813 - val_acc: 0.9618\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0824 - acc: 0.9612 - val_loss: 0.0811 - val_acc: 0.9616\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0821 - acc: 0.9612 - val_loss: 0.0811 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0800 - acc: 0.9618 - val_loss: 0.0792 - val_acc: 0.9621\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0798 - acc: 0.9619 - val_loss: 0.0789 - val_acc: 0.9621\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0795 - acc: 0.9620 - val_loss: 0.0791 - val_acc: 0.9620\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0794 - acc: 0.9620 - val_loss: 0.0790 - val_acc: 0.9620\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0794 - acc: 0.9621 - val_loss: 0.0788 - val_acc: 0.9620\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0792 - acc: 0.9621 - val_loss: 0.0790 - val_acc: 0.9620\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0792 - acc: 0.9622 - val_loss: 0.0789 - val_acc: 0.9620\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0791 - acc: 0.9622 - val_loss: 0.0783 - val_acc: 0.9620\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0788 - acc: 0.9622 - val_loss: 0.0788 - val_acc: 0.9620\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0787 - acc: 0.9622 - val_loss: 0.0791 - val_acc: 0.9620\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0788 - acc: 0.9623 - val_loss: 0.0792 - val_acc: 0.9621\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0787 - acc: 0.9622 - val_loss: 0.0786 - val_acc: 0.9620\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0786 - acc: 0.9623 - val_loss: 0.0787 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0774 - acc: 0.9627 - val_loss: 0.0777 - val_acc: 0.9623\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0772 - acc: 0.9628 - val_loss: 0.0780 - val_acc: 0.9622\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0773 - acc: 0.9627 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9628 - val_loss: 0.0780 - val_acc: 0.9621\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0771 - acc: 0.9629 - val_loss: 0.0780 - val_acc: 0.9622\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9628 - val_loss: 0.0781 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0764 - acc: 0.9630 - val_loss: 0.0777 - val_acc: 0.9624\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0764 - acc: 0.9631 - val_loss: 0.0775 - val_acc: 0.9623\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0763 - acc: 0.9630 - val_loss: 0.0773 - val_acc: 0.9624\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0763 - acc: 0.9631 - val_loss: 0.0774 - val_acc: 0.9623\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0763 - acc: 0.9631 - val_loss: 0.0773 - val_acc: 0.9623\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0763 - acc: 0.9631 - val_loss: 0.0775 - val_acc: 0.9623\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0773 - val_acc: 0.9624\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0774 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0759 - acc: 0.9632 - val_loss: 0.0772 - val_acc: 0.9625\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0759 - acc: 0.9632 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0771 - val_acc: 0.9624\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0771 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9624\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9624\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0757 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0755 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9626\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0771 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9626\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0755 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9626\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0771 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9626\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 83/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 84/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 85/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 86/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 87/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 88/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Epoch 89/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 90/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0770 - val_acc: 0.9625\n",
      "Fold 0.2 : Accuracy: 0.96250\n",
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1444 - acc: 0.9434 - val_loss: 0.1061 - val_acc: 0.9545\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1062 - acc: 0.9538 - val_loss: 0.0955 - val_acc: 0.9577\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.1004 - acc: 0.9557 - val_loss: 0.0915 - val_acc: 0.9590\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0968 - acc: 0.9568 - val_loss: 0.0919 - val_acc: 0.9583\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0945 - acc: 0.9575 - val_loss: 0.0884 - val_acc: 0.9597\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0927 - acc: 0.9582 - val_loss: 0.0903 - val_acc: 0.9591\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0915 - acc: 0.9585 - val_loss: 0.0892 - val_acc: 0.9592\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0903 - acc: 0.9589 - val_loss: 0.0871 - val_acc: 0.9598\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0895 - acc: 0.9591 - val_loss: 0.0866 - val_acc: 0.9601\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0887 - acc: 0.9593 - val_loss: 0.0856 - val_acc: 0.9604\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0878 - acc: 0.9594 - val_loss: 0.0871 - val_acc: 0.9597\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0869 - acc: 0.9598 - val_loss: 0.0850 - val_acc: 0.9605\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0864 - acc: 0.9601 - val_loss: 0.0852 - val_acc: 0.9602\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0859 - acc: 0.9601 - val_loss: 0.0845 - val_acc: 0.9601\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0853 - acc: 0.9603 - val_loss: 0.0839 - val_acc: 0.9605\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0846 - acc: 0.9606 - val_loss: 0.0829 - val_acc: 0.9610\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0843 - acc: 0.9607 - val_loss: 0.0824 - val_acc: 0.9611\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0840 - acc: 0.9608 - val_loss: 0.0825 - val_acc: 0.9610\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0835 - acc: 0.9609 - val_loss: 0.0823 - val_acc: 0.9610\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0832 - acc: 0.9609 - val_loss: 0.0836 - val_acc: 0.9608\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0829 - acc: 0.9611 - val_loss: 0.0827 - val_acc: 0.9607\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0826 - acc: 0.9611 - val_loss: 0.0815 - val_acc: 0.9610\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0823 - acc: 0.9611 - val_loss: 0.0817 - val_acc: 0.9612\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0821 - acc: 0.9613 - val_loss: 0.0817 - val_acc: 0.9610\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0818 - acc: 0.9613 - val_loss: 0.0816 - val_acc: 0.9610\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0816 - acc: 0.9614 - val_loss: 0.0815 - val_acc: 0.9610\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0815 - acc: 0.9614 - val_loss: 0.0819 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0793 - acc: 0.9622 - val_loss: 0.0796 - val_acc: 0.9617\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0791 - acc: 0.9622 - val_loss: 0.0803 - val_acc: 0.9614\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0790 - acc: 0.9622 - val_loss: 0.0796 - val_acc: 0.9615\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0788 - acc: 0.9623 - val_loss: 0.0794 - val_acc: 0.9616\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0787 - acc: 0.9622 - val_loss: 0.0791 - val_acc: 0.9618\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0786 - acc: 0.9623 - val_loss: 0.0795 - val_acc: 0.9616\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0785 - acc: 0.9623 - val_loss: 0.0794 - val_acc: 0.9615\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 20s 5ms/step - loss: 0.0784 - acc: 0.9624 - val_loss: 0.0791 - val_acc: 0.9615\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0784 - acc: 0.9624 - val_loss: 0.0805 - val_acc: 0.9611\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0783 - acc: 0.9624 - val_loss: 0.0793 - val_acc: 0.9614\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0771 - acc: 0.9628 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0770 - acc: 0.9628 - val_loss: 0.0784 - val_acc: 0.9619\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0769 - acc: 0.9629 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0769 - acc: 0.9629 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0767 - acc: 0.9629 - val_loss: 0.0789 - val_acc: 0.9618\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0767 - acc: 0.9629 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0763 - acc: 0.9630 - val_loss: 0.0781 - val_acc: 0.9618\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9630 - val_loss: 0.0780 - val_acc: 0.9619\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0781 - val_acc: 0.9618\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0779 - val_acc: 0.9618\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 25s 5ms/step - loss: 0.0760 - acc: 0.9631 - val_loss: 0.0780 - val_acc: 0.9618\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0760 - acc: 0.9631 - val_loss: 0.0780 - val_acc: 0.9617\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0760 - acc: 0.9631 - val_loss: 0.0779 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0757 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0756 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9618\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 20s 5ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0751 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 83/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00083: early stopping\n",
      "Fold 0.3 : Accuracy: 0.96197\n",
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1451 - acc: 0.9429 - val_loss: 0.1049 - val_acc: 0.9544\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1061 - acc: 0.9539 - val_loss: 0.0977 - val_acc: 0.9569\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1003 - acc: 0.9557 - val_loss: 0.0933 - val_acc: 0.9581\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0968 - acc: 0.9568 - val_loss: 0.0926 - val_acc: 0.9582\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0944 - acc: 0.9576 - val_loss: 0.0897 - val_acc: 0.9590\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0929 - acc: 0.9580 - val_loss: 0.0893 - val_acc: 0.9592\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0914 - acc: 0.9585 - val_loss: 0.0867 - val_acc: 0.9601\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0904 - acc: 0.9589 - val_loss: 0.0857 - val_acc: 0.9601\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0893 - acc: 0.9592 - val_loss: 0.0860 - val_acc: 0.9603\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0885 - acc: 0.9595 - val_loss: 0.0855 - val_acc: 0.9604\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0876 - acc: 0.9597 - val_loss: 0.0854 - val_acc: 0.9603\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0869 - acc: 0.9599 - val_loss: 0.0851 - val_acc: 0.9602\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0864 - acc: 0.9601 - val_loss: 0.0850 - val_acc: 0.9606\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0858 - acc: 0.9603 - val_loss: 0.0839 - val_acc: 0.9607\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0852 - acc: 0.9603 - val_loss: 0.0838 - val_acc: 0.9609\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0848 - acc: 0.9605 - val_loss: 0.0829 - val_acc: 0.9608\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0842 - acc: 0.9607 - val_loss: 0.0833 - val_acc: 0.9609\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0838 - acc: 0.9608 - val_loss: 0.0826 - val_acc: 0.9611\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0833 - acc: 0.9609 - val_loss: 0.0829 - val_acc: 0.9609\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0830 - acc: 0.9611 - val_loss: 0.0819 - val_acc: 0.9610\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0828 - acc: 0.9611 - val_loss: 0.0819 - val_acc: 0.9608\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0824 - acc: 0.9611 - val_loss: 0.0812 - val_acc: 0.9614\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0823 - acc: 0.9612 - val_loss: 0.0820 - val_acc: 0.9612\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0819 - acc: 0.9613 - val_loss: 0.0812 - val_acc: 0.9611\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0818 - acc: 0.9614 - val_loss: 0.0814 - val_acc: 0.9611\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0815 - acc: 0.9614 - val_loss: 0.0815 - val_acc: 0.9611\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0813 - acc: 0.9614 - val_loss: 0.0812 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0791 - acc: 0.9621 - val_loss: 0.0795 - val_acc: 0.9617\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0789 - acc: 0.9622 - val_loss: 0.0791 - val_acc: 0.9617\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0788 - acc: 0.9622 - val_loss: 0.0793 - val_acc: 0.9617\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0787 - acc: 0.9622 - val_loss: 0.0795 - val_acc: 0.9615\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0785 - acc: 0.9623 - val_loss: 0.0794 - val_acc: 0.9615\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0784 - acc: 0.9624 - val_loss: 0.0793 - val_acc: 0.9616\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0784 - acc: 0.9623 - val_loss: 0.0791 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0773 - acc: 0.9627 - val_loss: 0.0785 - val_acc: 0.9620\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9627 - val_loss: 0.0786 - val_acc: 0.9616\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0771 - acc: 0.9627 - val_loss: 0.0782 - val_acc: 0.9618\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9628 - val_loss: 0.0783 - val_acc: 0.9621\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0769 - acc: 0.9628 - val_loss: 0.0784 - val_acc: 0.9619\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0770 - acc: 0.9628 - val_loss: 0.0784 - val_acc: 0.9618\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0769 - acc: 0.9629 - val_loss: 0.0785 - val_acc: 0.9616\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0768 - acc: 0.9629 - val_loss: 0.0788 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0781 - val_acc: 0.9618\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0762 - acc: 0.9630 - val_loss: 0.0780 - val_acc: 0.9620\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0762 - acc: 0.9630 - val_loss: 0.0780 - val_acc: 0.9621\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0780 - val_acc: 0.9619\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0780 - val_acc: 0.9620\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0779 - val_acc: 0.9620\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0781 - val_acc: 0.9618\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0780 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0757 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9621\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0755 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 24s 5ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 83/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 84/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 85/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9633 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 86/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 87/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 88/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 89/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 90/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Fold 0.4 : Accuracy: 0.96202\n",
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1444 - acc: 0.9431 - val_loss: 0.1032 - val_acc: 0.9555\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1068 - acc: 0.9536 - val_loss: 0.0962 - val_acc: 0.9576\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1008 - acc: 0.9556 - val_loss: 0.0942 - val_acc: 0.9579\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0976 - acc: 0.9566 - val_loss: 0.0900 - val_acc: 0.9594\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0953 - acc: 0.9573 - val_loss: 0.0905 - val_acc: 0.9592\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0935 - acc: 0.9579 - val_loss: 0.0887 - val_acc: 0.9597\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0922 - acc: 0.9582 - val_loss: 0.0877 - val_acc: 0.9597\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0910 - acc: 0.9585 - val_loss: 0.0875 - val_acc: 0.9600\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0899 - acc: 0.9590 - val_loss: 0.0875 - val_acc: 0.9600\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0892 - acc: 0.9591 - val_loss: 0.0871 - val_acc: 0.9597\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0884 - acc: 0.9593 - val_loss: 0.0866 - val_acc: 0.9600\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0880 - acc: 0.9595 - val_loss: 0.0859 - val_acc: 0.9602\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0871 - acc: 0.9598 - val_loss: 0.0854 - val_acc: 0.9601\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0863 - acc: 0.9600 - val_loss: 0.0843 - val_acc: 0.9608\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0860 - acc: 0.9601 - val_loss: 0.0838 - val_acc: 0.9607\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0856 - acc: 0.9603 - val_loss: 0.0834 - val_acc: 0.9611\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0852 - acc: 0.9604 - val_loss: 0.0838 - val_acc: 0.9609\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0847 - acc: 0.9605 - val_loss: 0.0826 - val_acc: 0.9611\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0843 - acc: 0.9606 - val_loss: 0.0832 - val_acc: 0.9610\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0840 - acc: 0.9607 - val_loss: 0.0831 - val_acc: 0.9613\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0835 - acc: 0.9608 - val_loss: 0.0832 - val_acc: 0.9607\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0832 - acc: 0.9610 - val_loss: 0.0824 - val_acc: 0.9612\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0830 - acc: 0.9610 - val_loss: 0.0825 - val_acc: 0.9611\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0827 - acc: 0.9611 - val_loss: 0.0824 - val_acc: 0.9608\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0824 - acc: 0.9612 - val_loss: 0.0817 - val_acc: 0.9614\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0822 - acc: 0.9612 - val_loss: 0.0831 - val_acc: 0.9610\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0819 - acc: 0.9613 - val_loss: 0.0817 - val_acc: 0.9610\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0817 - acc: 0.9614 - val_loss: 0.0822 - val_acc: 0.9611\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0815 - acc: 0.9614 - val_loss: 0.0813 - val_acc: 0.9611\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0812 - acc: 0.9615 - val_loss: 0.0814 - val_acc: 0.9612\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0810 - acc: 0.9617 - val_loss: 0.0807 - val_acc: 0.9614\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0808 - acc: 0.9617 - val_loss: 0.0807 - val_acc: 0.9613\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0807 - acc: 0.9616 - val_loss: 0.0810 - val_acc: 0.9613\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0805 - acc: 0.9617 - val_loss: 0.0811 - val_acc: 0.9613\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0803 - acc: 0.9617 - val_loss: 0.0815 - val_acc: 0.9612\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0801 - acc: 0.9618 - val_loss: 0.0810 - val_acc: 0.9615\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0782 - acc: 0.9625 - val_loss: 0.0791 - val_acc: 0.9620\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0779 - acc: 0.9625 - val_loss: 0.0791 - val_acc: 0.9618\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0779 - acc: 0.9626 - val_loss: 0.0795 - val_acc: 0.9615\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0778 - acc: 0.9625 - val_loss: 0.0788 - val_acc: 0.9616\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0776 - acc: 0.9626 - val_loss: 0.0796 - val_acc: 0.9616\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0776 - acc: 0.9626 - val_loss: 0.0790 - val_acc: 0.9618\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0775 - acc: 0.9626 - val_loss: 0.0793 - val_acc: 0.9615\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0774 - acc: 0.9627 - val_loss: 0.0795 - val_acc: 0.9617\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0774 - acc: 0.9626 - val_loss: 0.0789 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0764 - acc: 0.9630 - val_loss: 0.0784 - val_acc: 0.9618\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0762 - acc: 0.9630 - val_loss: 0.0784 - val_acc: 0.9618\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0762 - acc: 0.9630 - val_loss: 0.0780 - val_acc: 0.9619\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0780 - val_acc: 0.9620\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9630 - val_loss: 0.0781 - val_acc: 0.9619\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9631 - val_loss: 0.0782 - val_acc: 0.9618\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0781 - val_acc: 0.9619\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0759 - acc: 0.9631 - val_loss: 0.0780 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0779 - val_acc: 0.9620\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9619\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9632 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9633 - val_loss: 0.0779 - val_acc: 0.9621\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0779 - val_acc: 0.9619\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0751 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9635 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0748 - acc: 0.9635 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0748 - acc: 0.9635 - val_loss: 0.0776 - val_acc: 0.9621\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9635 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0746 - acc: 0.9637 - val_loss: 0.0776 - val_acc: 0.9619\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0746 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0746 - acc: 0.9636 - val_loss: 0.0776 - val_acc: 0.9619\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 27s 6ms/step - loss: 0.0746 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0746 - acc: 0.9636 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0745 - acc: 0.9636 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0746 - acc: 0.9636 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0745 - acc: 0.9637 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0745 - acc: 0.9636 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0745 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9619\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0745 - acc: 0.9637 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 83/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0745 - acc: 0.9637 - val_loss: 0.0775 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 84/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 85/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9637 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 86/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0744 - acc: 0.9637 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 87/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 88/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9637 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 89/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 90/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0744 - acc: 0.9636 - val_loss: 0.0776 - val_acc: 0.9619\n",
      "Fold 0.5 : Accuracy: 0.96194\n",
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1463 - acc: 0.9428 - val_loss: 0.1063 - val_acc: 0.9542\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1065 - acc: 0.9537 - val_loss: 0.1012 - val_acc: 0.9557\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1001 - acc: 0.9560 - val_loss: 0.0931 - val_acc: 0.9585\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0968 - acc: 0.9569 - val_loss: 0.0929 - val_acc: 0.9584\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0948 - acc: 0.9575 - val_loss: 0.0904 - val_acc: 0.9591\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0931 - acc: 0.9581 - val_loss: 0.0901 - val_acc: 0.9589\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0919 - acc: 0.9585 - val_loss: 0.0896 - val_acc: 0.9591\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0909 - acc: 0.9587 - val_loss: 0.0884 - val_acc: 0.9596\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0900 - acc: 0.9590 - val_loss: 0.0863 - val_acc: 0.9600\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0889 - acc: 0.9593 - val_loss: 0.0858 - val_acc: 0.9601\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0884 - acc: 0.9595 - val_loss: 0.0865 - val_acc: 0.9596\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0875 - acc: 0.9597 - val_loss: 0.0861 - val_acc: 0.9599\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0870 - acc: 0.9600 - val_loss: 0.0841 - val_acc: 0.9604\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0864 - acc: 0.9601 - val_loss: 0.0841 - val_acc: 0.9603\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0859 - acc: 0.9602 - val_loss: 0.0844 - val_acc: 0.9603\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0854 - acc: 0.9604 - val_loss: 0.0843 - val_acc: 0.9605\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0850 - acc: 0.9604 - val_loss: 0.0844 - val_acc: 0.9603\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0845 - acc: 0.9606 - val_loss: 0.0836 - val_acc: 0.9606\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0842 - acc: 0.9607 - val_loss: 0.0825 - val_acc: 0.9610\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0838 - acc: 0.9608 - val_loss: 0.0831 - val_acc: 0.9608\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0837 - acc: 0.9608 - val_loss: 0.0832 - val_acc: 0.9606\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0832 - acc: 0.9610 - val_loss: 0.0831 - val_acc: 0.9607\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0830 - acc: 0.9610 - val_loss: 0.0821 - val_acc: 0.9611\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0829 - acc: 0.9611 - val_loss: 0.0824 - val_acc: 0.9610\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0825 - acc: 0.9612 - val_loss: 0.0828 - val_acc: 0.9608\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0823 - acc: 0.9612 - val_loss: 0.0818 - val_acc: 0.9611\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0820 - acc: 0.9612 - val_loss: 0.0827 - val_acc: 0.9612\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0818 - acc: 0.9614 - val_loss: 0.0831 - val_acc: 0.9606\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0815 - acc: 0.9615 - val_loss: 0.0818 - val_acc: 0.9611\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0814 - acc: 0.9614 - val_loss: 0.0817 - val_acc: 0.9611\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0812 - acc: 0.9615 - val_loss: 0.0828 - val_acc: 0.9608\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0791 - acc: 0.9623 - val_loss: 0.0806 - val_acc: 0.9614\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0789 - acc: 0.9623 - val_loss: 0.0799 - val_acc: 0.9615\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0787 - acc: 0.9624 - val_loss: 0.0801 - val_acc: 0.9610\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0786 - acc: 0.9624 - val_loss: 0.0804 - val_acc: 0.9612\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0785 - acc: 0.9624 - val_loss: 0.0802 - val_acc: 0.9614\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0785 - acc: 0.9624 - val_loss: 0.0799 - val_acc: 0.9616\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0784 - acc: 0.9625 - val_loss: 0.0799 - val_acc: 0.9614\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0772 - acc: 0.9628 - val_loss: 0.0795 - val_acc: 0.9616\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0770 - acc: 0.9629 - val_loss: 0.0794 - val_acc: 0.9617\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0770 - acc: 0.9629 - val_loss: 0.0791 - val_acc: 0.9617\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0770 - acc: 0.9628 - val_loss: 0.0794 - val_acc: 0.9614\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0770 - acc: 0.9629 - val_loss: 0.0792 - val_acc: 0.9617\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 27s 6ms/step - loss: 0.0769 - acc: 0.9628 - val_loss: 0.0793 - val_acc: 0.9617\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0768 - acc: 0.9628 - val_loss: 0.0789 - val_acc: 0.9618\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0767 - acc: 0.9629 - val_loss: 0.0791 - val_acc: 0.9617\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0767 - acc: 0.9630 - val_loss: 0.0791 - val_acc: 0.9616\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.0766 - acc: 0.9630 - val_loss: 0.0795 - val_acc: 0.9614\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0766 - acc: 0.9630 - val_loss: 0.0794 - val_acc: 0.9616\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0766 - acc: 0.9630 - val_loss: 0.0790 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0787 - val_acc: 0.9617\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0759 - acc: 0.9633 - val_loss: 0.0788 - val_acc: 0.9617\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0787 - val_acc: 0.9619\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0758 - acc: 0.9633 - val_loss: 0.0787 - val_acc: 0.9616\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0759 - acc: 0.9632 - val_loss: 0.0788 - val_acc: 0.9617\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0787 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0755 - acc: 0.9634 - val_loss: 0.0786 - val_acc: 0.9617\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0786 - val_acc: 0.9618\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0786 - val_acc: 0.9617\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0786 - val_acc: 0.9617\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0787 - val_acc: 0.9617\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0754 - acc: 0.9633 - val_loss: 0.0786 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0786 - val_acc: 0.9618\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0786 - val_acc: 0.9618\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0786 - val_acc: 0.9617\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0786 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0786 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0750 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 83/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0750 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 84/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0750 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 85/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 86/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 87/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 88/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0785 - val_acc: 0.9617\n",
      "Epoch 89/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "Epoch 90/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0750 - acc: 0.9636 - val_loss: 0.0785 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Fold 0.6 : Accuracy: 0.96178\n",
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1452 - acc: 0.9430 - val_loss: 0.1071 - val_acc: 0.9541\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1066 - acc: 0.9537 - val_loss: 0.0983 - val_acc: 0.9568\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.1008 - acc: 0.9555 - val_loss: 0.0944 - val_acc: 0.9581\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0974 - acc: 0.9567 - val_loss: 0.0908 - val_acc: 0.9591\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0949 - acc: 0.9574 - val_loss: 0.0893 - val_acc: 0.9597\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0934 - acc: 0.9579 - val_loss: 0.0913 - val_acc: 0.9583\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0917 - acc: 0.9584 - val_loss: 0.0873 - val_acc: 0.9603\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0906 - acc: 0.9587 - val_loss: 0.0859 - val_acc: 0.9606\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0897 - acc: 0.9590 - val_loss: 0.0855 - val_acc: 0.9605\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0887 - acc: 0.9593 - val_loss: 0.0865 - val_acc: 0.9603\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0881 - acc: 0.9595 - val_loss: 0.0853 - val_acc: 0.9603\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0873 - acc: 0.9597 - val_loss: 0.0838 - val_acc: 0.9609\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0866 - acc: 0.9600 - val_loss: 0.0838 - val_acc: 0.9608\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0860 - acc: 0.9601 - val_loss: 0.0849 - val_acc: 0.9605\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0854 - acc: 0.9603 - val_loss: 0.0822 - val_acc: 0.9614\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0850 - acc: 0.9603 - val_loss: 0.0831 - val_acc: 0.9609\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0845 - acc: 0.9606 - val_loss: 0.0826 - val_acc: 0.9613\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0842 - acc: 0.9606 - val_loss: 0.0824 - val_acc: 0.9612\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0838 - acc: 0.9607 - val_loss: 0.0829 - val_acc: 0.9612\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0834 - acc: 0.9608 - val_loss: 0.0828 - val_acc: 0.9611\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0811 - acc: 0.9616 - val_loss: 0.0797 - val_acc: 0.9619\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0807 - acc: 0.9617 - val_loss: 0.0800 - val_acc: 0.9617\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0805 - acc: 0.9617 - val_loss: 0.0806 - val_acc: 0.9616\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0804 - acc: 0.9618 - val_loss: 0.0800 - val_acc: 0.9619\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0803 - acc: 0.9618 - val_loss: 0.0804 - val_acc: 0.9616\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0800 - acc: 0.9619 - val_loss: 0.0801 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0788 - acc: 0.9623 - val_loss: 0.0790 - val_acc: 0.9619\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0787 - acc: 0.9624 - val_loss: 0.0787 - val_acc: 0.9621\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0786 - acc: 0.9624 - val_loss: 0.0790 - val_acc: 0.9620\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0785 - acc: 0.9624 - val_loss: 0.0787 - val_acc: 0.9619\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0784 - acc: 0.9624 - val_loss: 0.0790 - val_acc: 0.9620\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0783 - acc: 0.9624 - val_loss: 0.0788 - val_acc: 0.9621\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0783 - acc: 0.9624 - val_loss: 0.0784 - val_acc: 0.9621\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0782 - acc: 0.9625 - val_loss: 0.0788 - val_acc: 0.9621\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0782 - acc: 0.9625 - val_loss: 0.0789 - val_acc: 0.9620\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0781 - acc: 0.9625 - val_loss: 0.0787 - val_acc: 0.9618\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0781 - acc: 0.9625 - val_loss: 0.0786 - val_acc: 0.9620\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0779 - acc: 0.9626 - val_loss: 0.0784 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0774 - acc: 0.9627 - val_loss: 0.0782 - val_acc: 0.9622\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0772 - acc: 0.9628 - val_loss: 0.0782 - val_acc: 0.9621\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 25s 6ms/step - loss: 0.0772 - acc: 0.9628 - val_loss: 0.0781 - val_acc: 0.9622\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 21s 5ms/step - loss: 0.0772 - acc: 0.9628 - val_loss: 0.0782 - val_acc: 0.9623\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0771 - acc: 0.9629 - val_loss: 0.0782 - val_acc: 0.9621\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0771 - acc: 0.9628 - val_loss: 0.0784 - val_acc: 0.9621\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0770 - acc: 0.9628 - val_loss: 0.0782 - val_acc: 0.9621\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0770 - acc: 0.9628 - val_loss: 0.0782 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0768 - acc: 0.9629 - val_loss: 0.0780 - val_acc: 0.9623\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0766 - acc: 0.9629 - val_loss: 0.0780 - val_acc: 0.9624\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0767 - acc: 0.9630 - val_loss: 0.0780 - val_acc: 0.9622\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0766 - acc: 0.9629 - val_loss: 0.0780 - val_acc: 0.9624\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0765 - acc: 0.9630 - val_loss: 0.0780 - val_acc: 0.9623\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0766 - acc: 0.9630 - val_loss: 0.0779 - val_acc: 0.9624\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0765 - acc: 0.9630 - val_loss: 0.0779 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0764 - acc: 0.9630 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0763 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0764 - acc: 0.9631 - val_loss: 0.0779 - val_acc: 0.9623\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0763 - acc: 0.9631 - val_loss: 0.0779 - val_acc: 0.9623\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0763 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0763 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0762 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0762 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9624\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9624\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0762 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9624\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9631 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9624\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 83/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 84/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 85/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 86/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 87/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Epoch 88/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 89/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 90/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9623\n",
      "Fold 0.7 : Accuracy: 0.96230\n",
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1459 - acc: 0.9427 - val_loss: 0.1065 - val_acc: 0.9541\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.1072 - acc: 0.9535 - val_loss: 0.0998 - val_acc: 0.9558\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 20s 4ms/step - loss: 0.1010 - acc: 0.9555 - val_loss: 0.0942 - val_acc: 0.9577\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0978 - acc: 0.9565 - val_loss: 0.0930 - val_acc: 0.9580\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0953 - acc: 0.9573 - val_loss: 0.0918 - val_acc: 0.9585\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0936 - acc: 0.9579 - val_loss: 0.0893 - val_acc: 0.9590\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0919 - acc: 0.9584 - val_loss: 0.0915 - val_acc: 0.9583\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0905 - acc: 0.9589 - val_loss: 0.0865 - val_acc: 0.9602\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0897 - acc: 0.9591 - val_loss: 0.0860 - val_acc: 0.9602\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0888 - acc: 0.9593 - val_loss: 0.0873 - val_acc: 0.9598\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0880 - acc: 0.9596 - val_loss: 0.0895 - val_acc: 0.9590\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0874 - acc: 0.9597 - val_loss: 0.0841 - val_acc: 0.9608\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0867 - acc: 0.9600 - val_loss: 0.0840 - val_acc: 0.9607\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0862 - acc: 0.9601 - val_loss: 0.0842 - val_acc: 0.9607\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0857 - acc: 0.9603 - val_loss: 0.0834 - val_acc: 0.9608\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0853 - acc: 0.9604 - val_loss: 0.0841 - val_acc: 0.9606\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0848 - acc: 0.9606 - val_loss: 0.0835 - val_acc: 0.9606\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0845 - acc: 0.9606 - val_loss: 0.0828 - val_acc: 0.9610\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0843 - acc: 0.9606 - val_loss: 0.0824 - val_acc: 0.9610\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0837 - acc: 0.9609 - val_loss: 0.0824 - val_acc: 0.9610\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0834 - acc: 0.9610 - val_loss: 0.0839 - val_acc: 0.9606\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0832 - acc: 0.9610 - val_loss: 0.0825 - val_acc: 0.9610\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0830 - acc: 0.9610 - val_loss: 0.0820 - val_acc: 0.9613\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0827 - acc: 0.9611 - val_loss: 0.0812 - val_acc: 0.9613\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0824 - acc: 0.9612 - val_loss: 0.0816 - val_acc: 0.9608\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0821 - acc: 0.9613 - val_loss: 0.0817 - val_acc: 0.9610\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0818 - acc: 0.9613 - val_loss: 0.0807 - val_acc: 0.9613\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0817 - acc: 0.9613 - val_loss: 0.0811 - val_acc: 0.9614\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0815 - acc: 0.9615 - val_loss: 0.0810 - val_acc: 0.9613\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0812 - acc: 0.9616 - val_loss: 0.0807 - val_acc: 0.9615\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0810 - acc: 0.9616 - val_loss: 0.0812 - val_acc: 0.9611\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0809 - acc: 0.9617 - val_loss: 0.0811 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0789 - acc: 0.9623 - val_loss: 0.0792 - val_acc: 0.9618\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0785 - acc: 0.9623 - val_loss: 0.0796 - val_acc: 0.9617\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0784 - acc: 0.9624 - val_loss: 0.0789 - val_acc: 0.9618\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0784 - acc: 0.9625 - val_loss: 0.0792 - val_acc: 0.9616\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0782 - acc: 0.9624 - val_loss: 0.0791 - val_acc: 0.9618\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0782 - acc: 0.9624 - val_loss: 0.0796 - val_acc: 0.9617\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0781 - acc: 0.9625 - val_loss: 0.0790 - val_acc: 0.9615\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0780 - acc: 0.9625 - val_loss: 0.0788 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0770 - acc: 0.9629 - val_loss: 0.0782 - val_acc: 0.9619\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0768 - acc: 0.9629 - val_loss: 0.0784 - val_acc: 0.9618\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0767 - acc: 0.9630 - val_loss: 0.0782 - val_acc: 0.9619\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0767 - acc: 0.9629 - val_loss: 0.0783 - val_acc: 0.9618\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0766 - acc: 0.9631 - val_loss: 0.0781 - val_acc: 0.9618\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0767 - acc: 0.9630 - val_loss: 0.0782 - val_acc: 0.9621\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0765 - acc: 0.9630 - val_loss: 0.0784 - val_acc: 0.9618\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0765 - acc: 0.9630 - val_loss: 0.0785 - val_acc: 0.9620\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0764 - acc: 0.9630 - val_loss: 0.0783 - val_acc: 0.9619\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0764 - acc: 0.9631 - val_loss: 0.0782 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0758 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0758 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0779 - val_acc: 0.9620\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0757 - acc: 0.9632 - val_loss: 0.0777 - val_acc: 0.9621\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0757 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0757 - acc: 0.9633 - val_loss: 0.0778 - val_acc: 0.9620\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0757 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0777 - val_acc: 0.9621\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0756 - acc: 0.9632 - val_loss: 0.0778 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 22s 5ms/step - loss: 0.0752 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0777 - val_acc: 0.9620\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0776 - val_acc: 0.9620\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0777 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 26s 6ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 23s 5ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9622\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0750 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0751 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0749 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0749 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 78/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 79/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 80/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 81/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0749 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 82/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9635 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 83/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 84/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 85/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 86/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 87/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 88/90\n",
      "4500/4500 [==============================] - 19s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Epoch 89/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0749 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9621\n",
      "Epoch 90/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0748 - acc: 0.9636 - val_loss: 0.0775 - val_acc: 0.9620\n",
      "Fold 0.8 : Accuracy: 0.96203\n",
      "Epoch 1/90\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.1464 - acc: 0.9427 - val_loss: 0.1033 - val_acc: 0.9555\n",
      "Epoch 2/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.1068 - acc: 0.9536 - val_loss: 0.0983 - val_acc: 0.9567\n",
      "Epoch 3/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.1007 - acc: 0.9556 - val_loss: 0.0933 - val_acc: 0.9582\n",
      "Epoch 4/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0973 - acc: 0.9567 - val_loss: 0.0906 - val_acc: 0.9590\n",
      "Epoch 5/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0950 - acc: 0.9575 - val_loss: 0.0893 - val_acc: 0.9597\n",
      "Epoch 6/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0935 - acc: 0.9580 - val_loss: 0.0884 - val_acc: 0.9595\n",
      "Epoch 7/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0917 - acc: 0.9585 - val_loss: 0.0875 - val_acc: 0.9599\n",
      "Epoch 8/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0907 - acc: 0.9588 - val_loss: 0.0858 - val_acc: 0.9603\n",
      "Epoch 9/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0896 - acc: 0.9592 - val_loss: 0.0875 - val_acc: 0.9597\n",
      "Epoch 10/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0889 - acc: 0.9594 - val_loss: 0.0856 - val_acc: 0.9602\n",
      "Epoch 11/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0883 - acc: 0.9594 - val_loss: 0.0841 - val_acc: 0.9609\n",
      "Epoch 12/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0876 - acc: 0.9598 - val_loss: 0.0848 - val_acc: 0.9607\n",
      "Epoch 13/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0869 - acc: 0.9600 - val_loss: 0.0852 - val_acc: 0.9603\n",
      "Epoch 14/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0865 - acc: 0.9601 - val_loss: 0.0842 - val_acc: 0.9605\n",
      "Epoch 15/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0859 - acc: 0.9602 - val_loss: 0.0853 - val_acc: 0.9602\n",
      "Epoch 16/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0855 - acc: 0.9603 - val_loss: 0.0831 - val_acc: 0.9612\n",
      "Epoch 17/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0850 - acc: 0.9605 - val_loss: 0.0831 - val_acc: 0.9611\n",
      "Epoch 18/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0847 - acc: 0.9606 - val_loss: 0.0824 - val_acc: 0.9613\n",
      "Epoch 19/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0844 - acc: 0.9608 - val_loss: 0.0848 - val_acc: 0.9604\n",
      "Epoch 20/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0839 - acc: 0.9609 - val_loss: 0.0827 - val_acc: 0.9609\n",
      "Epoch 21/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0837 - acc: 0.9609 - val_loss: 0.0827 - val_acc: 0.9611\n",
      "Epoch 22/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0832 - acc: 0.9610 - val_loss: 0.0828 - val_acc: 0.9610\n",
      "Epoch 23/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0830 - acc: 0.9610 - val_loss: 0.0820 - val_acc: 0.9613\n",
      "Epoch 24/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0827 - acc: 0.9611 - val_loss: 0.0827 - val_acc: 0.9611\n",
      "Epoch 25/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0824 - acc: 0.9612 - val_loss: 0.0828 - val_acc: 0.9609\n",
      "Epoch 26/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0822 - acc: 0.9613 - val_loss: 0.0810 - val_acc: 0.9614\n",
      "Epoch 27/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0820 - acc: 0.9614 - val_loss: 0.0822 - val_acc: 0.9612\n",
      "Epoch 28/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0817 - acc: 0.9614 - val_loss: 0.0808 - val_acc: 0.9616\n",
      "Epoch 29/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0816 - acc: 0.9614 - val_loss: 0.0806 - val_acc: 0.9617\n",
      "Epoch 30/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0813 - acc: 0.9616 - val_loss: 0.0814 - val_acc: 0.9613\n",
      "Epoch 31/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0812 - acc: 0.9616 - val_loss: 0.0828 - val_acc: 0.9611\n",
      "Epoch 32/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0810 - acc: 0.9617 - val_loss: 0.0812 - val_acc: 0.9612\n",
      "Epoch 33/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0809 - acc: 0.9616 - val_loss: 0.0824 - val_acc: 0.9610\n",
      "Epoch 34/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0807 - acc: 0.9617 - val_loss: 0.0812 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 35/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0788 - acc: 0.9623 - val_loss: 0.0793 - val_acc: 0.9618\n",
      "Epoch 36/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0785 - acc: 0.9624 - val_loss: 0.0794 - val_acc: 0.9620\n",
      "Epoch 37/90\n",
      "4500/4500 [==============================] - 15s 3ms/step - loss: 0.0783 - acc: 0.9624 - val_loss: 0.0789 - val_acc: 0.9618\n",
      "Epoch 38/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0784 - acc: 0.9625 - val_loss: 0.0794 - val_acc: 0.9619\n",
      "Epoch 39/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0782 - acc: 0.9625 - val_loss: 0.0791 - val_acc: 0.9619\n",
      "Epoch 40/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0781 - acc: 0.9626 - val_loss: 0.0797 - val_acc: 0.9617\n",
      "Epoch 41/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0781 - acc: 0.9625 - val_loss: 0.0792 - val_acc: 0.9617\n",
      "Epoch 42/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0781 - acc: 0.9625 - val_loss: 0.0791 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 43/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0769 - acc: 0.9629 - val_loss: 0.0784 - val_acc: 0.9621\n",
      "Epoch 44/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0769 - acc: 0.9629 - val_loss: 0.0786 - val_acc: 0.9622\n",
      "Epoch 45/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0769 - acc: 0.9630 - val_loss: 0.0788 - val_acc: 0.9619\n",
      "Epoch 46/90\n",
      "4500/4500 [==============================] - 18s 4ms/step - loss: 0.0767 - acc: 0.9630 - val_loss: 0.0786 - val_acc: 0.9620\n",
      "Epoch 47/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0767 - acc: 0.9630 - val_loss: 0.0785 - val_acc: 0.9619\n",
      "Epoch 48/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0766 - acc: 0.9631 - val_loss: 0.0784 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 49/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0761 - acc: 0.9633 - val_loss: 0.0780 - val_acc: 0.9620\n",
      "Epoch 50/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0761 - acc: 0.9632 - val_loss: 0.0780 - val_acc: 0.9622\n",
      "Epoch 51/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0760 - acc: 0.9632 - val_loss: 0.0780 - val_acc: 0.9620\n",
      "Epoch 52/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0760 - acc: 0.9633 - val_loss: 0.0780 - val_acc: 0.9621\n",
      "Epoch 53/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0760 - acc: 0.9633 - val_loss: 0.0781 - val_acc: 0.9621\n",
      "Epoch 54/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0759 - acc: 0.9632 - val_loss: 0.0780 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 55/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0756 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 56/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0780 - val_acc: 0.9620\n",
      "Epoch 57/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0756 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 58/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0756 - acc: 0.9633 - val_loss: 0.0779 - val_acc: 0.9622\n",
      "Epoch 59/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0756 - acc: 0.9634 - val_loss: 0.0779 - val_acc: 0.9622\n",
      "Epoch 60/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0756 - acc: 0.9634 - val_loss: 0.0779 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 61/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0754 - acc: 0.9635 - val_loss: 0.0779 - val_acc: 0.9621\n",
      "Epoch 62/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0754 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 63/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0754 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 64/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0754 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 65/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0779 - val_acc: 0.9622\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 66/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 67/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 68/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 69/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0753 - acc: 0.9634 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 70/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0753 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 71/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 72/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 73/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 74/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Epoch 75/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 76/90\n",
      "4500/4500 [==============================] - 14s 3ms/step - loss: 0.0751 - acc: 0.9636 - val_loss: 0.0778 - val_acc: 0.9622\n",
      "Epoch 77/90\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.0752 - acc: 0.9635 - val_loss: 0.0778 - val_acc: 0.9621\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00077: early stopping\n",
      "Fold 0.9 : Accuracy: 0.96215\n"
     ]
    }
   ],
   "source": [
    "score_list, test_pred_list, history_list = [], [], []\n",
    "\n",
    "EPOCHS = 90\n",
    "VERBOSE = 1\n",
    "SINGLE_FOLD = False   \n",
    "BATCH_SIZE = 800\n",
    "FOLDS = 10\n",
    "RUNS = 1  # should be 1. increase the number of runs only if you want see how the result depends on the random seed\n",
    "\n",
    "def my_model(X):\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(X.shape[-1])))\n",
    "    model.add(Dense(128, activation='selu'))\n",
    "    model.add(BatchNormalization())\n",
    "   # model.add(Dropout(.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(.1))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "for run in range(RUNS):\n",
    "    kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=1)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y=y)):\n",
    "        X_tr = X.iloc[train_idx]\n",
    "        X_va = X.iloc[val_idx]\n",
    "        y_tr = y.iloc[train_idx]\n",
    "        y_va = y.iloc[val_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        X_tr = pd.DataFrame(scaler.fit_transform(X_tr))\n",
    "        X_va = pd.DataFrame(scaler.transform(X_va))\n",
    "        \n",
    "        model = my_model(X_tr)\n",
    "\n",
    "        #define callbacks\n",
    "        lr = ReduceLROnPlateau(monitor='val_loss', factor=.5, patience=5, verbose=VERBOSE)\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=10, verbose=VERBOSE, mode='min', restore_best_weights=True)\n",
    "\n",
    "#train and save model\n",
    "        history = model.fit(X_tr, y_tr, validation_data=(X_va, y_va), epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                            validation_batch_size= len(X_va), callbacks=[lr,es], shuffle=True)\n",
    "\n",
    "        history_list.append(history.history)\n",
    "        model.save(f'model{run}.{fold}')\n",
    "\n",
    "        #inference for validation after last epoch of fold\n",
    "        y_va_pred = model.predict(X_va, batch_size=len(X_va))\n",
    "        y_va_pred = np.argmax(y_va_pred, axis=1)\n",
    "\n",
    "        #evaluation\n",
    "        accuracy = accuracy_score(y_va, y_va_pred)\n",
    "\n",
    "        print(f'Fold {run}.{fold} : Accuracy: {accuracy:.5f}')\n",
    "\n",
    "        #test predicts\n",
    "        test_pred_list.append(model.predict(scaler.transform(X_test), batch_size=BATCH_SIZE))\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test['Id']\n",
    "sub['Cover_Type'] = le.inverse_transform(np.argmax(sum(test_pred_list), axis=1))\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16680.83677,
   "end_time": "2021-12-15T17:46:54.388693",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-15T13:08:53.551923",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
